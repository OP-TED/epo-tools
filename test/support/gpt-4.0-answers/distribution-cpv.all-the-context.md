## Giving the complete ontology as context

The LLM does not follow the instructions given. 

The signal of instructions are diluted when the context is too big, it tends to allucinate. Also the context window is not enough to continue with a conversation. 

The context needs to be smaller for meaninful responses. 

Question: What is the smallest context that contains the necessary information?
